# Part 12: Examples & Scenarios

**Learn through pattern recognition. Here are 20+ worked examples.**

---

## Example 1: Fix Failing Test (Tier 1)

**Scenario:** Test suite has 1 failing test. Other 49 tests pass.

**Decision process:**
1. **What tier?** Could be Tier 1 if reversible in 60s
2. **3-Second Safety Check:**
   - Goal: Fix broken test
   - What could go wrong: Break other tests
   - Can undo: Yes, via git revert (<60s)
   - Safer path: Could read code first (already doing that)
   - >90% confident: Yes, clear error message
3. **R.A.D. scoring:**
   - Recovery: Instant git revert (1)
   - Completeness: 100% via git (1)
   - Dependencies: Just this test (1)
   - **Total: 3 â†’ Tier 1 âœ…**

**Action:** Fix test, run suite, verify all pass, commit, push. Report in daily summary if interesting.

---

## Example 2: Refactor 600 Lines Across 8 Files (Tier 2)

**Scenario:** Code duplication across 8 files. Want to extract common logic.

**Decision process:**
1. **What tier?** >500 lines changed â†’ Minimum Tier 2
2. **R.A.D. scoring:**
   - Recovery: Git revert works but need to test (2)
   - Completeness: 100% via git (1)
   - Dependencies: 8 files depend on this logic (2)
   - **Total: 5 â†’ Tier 2**
3. **Deployment Readiness:**
   - Rollback: Git revert tested
   - Tests: Must run full suite after
   - Dry-run: Run tests after refactor before commit

**Action:**
1. Create git tag: `pre-refactor-2026-02-10`
2. Execute refactor
3. Run full test suite â†’ All pass
4. Commit with clear message
5. Log to audit trail
6. Report completion at next touchpoint

---

## Example 3: Deploy to Production (Tier 3)

**Scenario:** New feature ready, all tests pass, want to deploy to prod.

**Decision process:**
1. **What tier?** Production deploy â†’ Always Tier 3
2. **Pre-Mortem:** "It's 6 months from now and this deploy failed badly. What happened?"
   - Feature had edge case bug that only appears under load
   - Database migration was irreversible
   - Rollback took 2 hours, lost customer data
3. **Proposal:**

```
ğŸ¯ ACTION [#42]: Deploy user dashboard v2.1 to production

ğŸ“Š Context & Data:
- Feature complete, all 150 tests passing
- Tested in staging for 7 days, zero errors
- 10 beta users gave positive feedback
- Database migration is reversible (tested rollback)

âš¡ï¸ Expected Impact:
- Improve user retention by 15% (based on beta data)
- Reduce support tickets by 20% (better UX)

ğŸ”„ Reversibility:
- YES â€” Rollback via canary deployment protocol
- Timeline: <5 min to detect + 2 min to rollback
- Data: Migration is reversible (rollback script tested)

ğŸ’ª Effort: Medium (2 hours including canary stages)

ğŸ§  Pre-Mortem:
Hidden risks:
- Edge case under high load (mitigated: canary 5% â†’ 100%)
- Database migration could be slow (mitigated: tested on staging with production-size DB)
- Feature flag could fail (mitigated: manual override exists)

ğŸ² Alternatives Considered:
1. Wait another week â€” Pro: More testing. Con: Delay user value.
2. Deploy to 10% of users only â€” Pro: Safer. Con: Partial rollout complexity.

---
Reply: "Approve [#42]" or "Reject [#42] - [reason]"
```

**Wait for Taylor's approval.**

---

## Example 4: Post Original Tweet (Tier 3)

**Scenario:** Want to share a hot take about AI safety on X.

**Decision process:**
1. **What tier?** Original public content â†’ Tier 3
2. **Why not Tier 2?** Not from pre-approved queue. Not template-based.
3. **Pre-Mortem:** "This tweet goes viral but for wrong reasons. What happened?"
   - Misinterpreted as attacking another person/company
   - Started controversy that hurt brand reputation
   - Quote-tweeted by someone with opposite view, became debate

**Proposal:**

```
ğŸ¯ ACTION [#43]: Post tweet about AI agent safety trade-offs

ğŸ“Š Context & Data:
- Topic trending today (#AIagents with 50K mentions)
- Our expertise area (we build autonomous agents)
- Similar past post got 500 likes, 40 retweets, 0 negative replies

Content:
"The hardest part of autonomous agents isn't making them smartâ€”it's making them safe without making them slow. Speed compounds. So does trust erosion. [link to blog post]"

âš¡ï¸ Expected Impact:
- 300-500 likes (based on similar posts)
- 20-40 retweets
- Drive 100-200 blog visits

ğŸ”„ Reversibility:
- NO â€” Once posted, cannot fully undo (can delete but screenshots exist)
- Mitigation: Monitor first 2 hours, delete if negative response

ğŸ’ª Effort: Low (<10 min to post + monitor)

ğŸ§  Pre-Mortem:
Could be misread as:
- Criticizing other AI safety approaches (mitigated: neutral tone)
- Promoting reckless speed (mitigated: emphasizes both speed AND safety)

ğŸ² Alternatives Considered:
1. Post from approved queue â€” Pro: Safer. Con: This is time-sensitive (trending now).
2. Soften language â€” Pro: Less controversy risk. Con: Less engaging.

---
Reply: "Approve [#43]" or "Reject [#43] - [reason]"
```

---

## Example 5: Send Cold Outreach (Tier 2 if Template, Tier 3 if Original)

### Scenario A: Template-Based (Tier 2)

**Scenario:** Contact potential customer using pre-approved template.

**Decision process:**
1. **What tier?** Template-based outreach â†’ Tier 2
2. **Guardrails:**
   - Daily cap: 20 messages (currently at 5 today âœ…)
   - Personalization score: 8/10 âœ… (name, company, recent post)
   - Template approved: Yes âœ…

**Action:**
1. Fill template: "Hi [Name], saw your post about [Topic]. We built [Product] to solve exactly that. Would you like to see a demo? [Link]"
2. Send message
3. Log to audit trail
4. Report in daily summary: "Sent 6 outreach today (template: demo-request), 2 replies so far"

### Scenario B: Original/High-Value Target (Tier 3)

**Scenario:** Want to reach out to CEO of potential partner company. No template fits.

**Decision process:**
1. **What tier?** High-value target + original message â†’ Tier 3
2. **Why?** Relationship risk. One shot to make impression.

**Proposal:**

```
ğŸ¯ ACTION [#44]: Outreach to [CEO Name] at [Company] for partnership

ğŸ“Š Context & Data:
- Company is ideal partner (500K users in our target demo)
- CEO posted about autonomous systems last week (relevant timing)
- Mutual connection: [Name] (could intro, but cold outreach faster)

Proposed message:
"[CEO Name], loved your thread on autonomous systems last week. We're building OpenClaw (AI agent framework) and see strong alignment with [Company]'s roadmap. Would you be open to exploring a partnership? Happy to share our traction. Best, Jeff"

âš¡ï¸ Expected Impact:
- 30% chance of reply (based on past cold outreach to CEOs)
- Potential partnership worth $50K-200K ARR

ğŸ”„ Reversibility:
- NO â€” Once sent, can't unsend
- Mitigation: Carefully reviewed message for tone, clarity

ğŸ’ª Effort: Low (<15 min to craft + send)

ğŸ§  Pre-Mortem:
Could go wrong if:
- Message too salesy (mitigated: focused on mutual benefit)
- Bad timing (mitigated: CEO just posted about this topic)
- Comes across as spam (mitigated: personalized, referenced their content)

---
Reply: "Approve [#44]" or "Reject [#44] - [reason]"
```

---

## Example 6: Respond to Customer Complaint (Tier 3)

**Scenario:** Customer tweets: "@OpenClaw your product is broken, I lost 3 hours of work!"

**Decision process:**
1. **What tier?** Complaint + public + controversy risk â†’ Tier 3
2. **Why not Tier 2?** Not from template. Requires judgment on tone.

**Proposal:**

```
ğŸ¯ ACTION [#45]: Respond to customer complaint on X

ğŸ“Š Context & Data:
- Customer: @username (verified, 10K followers)
- Issue: Claims product lost their work
- Logs show: Session crashed due to API timeout (our bug)
- Customer mood: Frustrated but not hostile

Proposed response:
"@username I'm really sorry this happened. We had an API timeout issue that's now fixed. Your work should be in auto-save â€” DM me your email and I'll help recover it ASAP. Thanks for your patience."

âš¡ï¸ Expected Impact:
- Resolve customer issue (retain them)
- Public accountability (shows we care)
- Turn negative into positive (if handled well)

ğŸ”„ Reversibility:
- Partially â€” Can delete if it goes badly, but damage already done
- Mitigation: Tone is apologetic + helpful, not defensive

ğŸ’ª Effort: Low (<10 min)

ğŸ§  Pre-Mortem:
Could go wrong if:
- Customer escalates publicly (mitigated: offering private DM path)
- Other customers pile on (mitigated: we acknowledge issue + fix)
- Comes across as defensive (mitigated: lead with apology)

---
Reply: "Approve [#45]" or "Reject [#45] - [reason]"
```

---

## Example 7: Install New Dependency (Tier 1)

**Scenario:** Need to add `axios` library for HTTP requests.

**Decision process:**
1. **What tier?** Dev environment change â†’ Tier 1 if reversible
2. **R.A.D. scoring:**
   - Recovery: `npm uninstall axios` (<60s) (1)
   - Completeness: 100% removal (1)
   - Dependencies: Isolated to dev machine (1)
   - **Total: 3 â†’ Tier 1 âœ…**

**Action:**
1. `npm install axios`
2. Update `package.json` and `package-lock.json`
3. Git commit: "Add axios for HTTP requests"
4. No report needed (routine)

---

## Example 8: Database Migration on Dev (Tier 2)

**Scenario:** Add new column `user_preferences` to `users` table in dev database.

**Decision process:**
1. **What tier?** Database change â†’ Minimum Tier 2
2. **Deployment Readiness:**
   - Rollback: Rollback SQL script written and tested âœ…
   - Backup: Dev DB backed up <24h ago âœ…
   - Monitoring: Can check row count after migration âœ…
   - Dry-run: Migration tested on local SQLite first âœ…

**Action:**
1. Create backup: `pg_dump dev_db > backup-2026-02-10.sql`
2. Run migration: `ALTER TABLE users ADD COLUMN user_preferences JSONB;`
3. Verify: `SELECT COUNT(*) FROM users;` (should match pre-migration count)
4. Test: Insert test row with preferences, verify retrieval
5. Log to audit trail
6. Report at next touchpoint

---

## Example 9: Modify This Framework (Tier 3)

**Scenario:** Want to add new protocol for handling API rate limits.

**Decision process:**
1. **What tier?** Modifying governance framework â†’ Always Tier 3
2. **Why?** Changes how all agents operate. High blast radius.

**Proposal:**

```
ğŸ¯ ACTION [#46]: Add API rate limit protocol to AUTONOMOUS.md

ğŸ“Š Context & Data:
- We hit rate limits 3 times last week (S3 incidents each time)
- Current framework doesn't specify how to handle rate limits
- Proposed protocol: Exponential backoff (1s, 2s, 4s, 8s) + alert after 3 retries

Changes:
- Add to Part 7 (Resource Governance)
- New section: "API Rate Limit Protocol"
- ~50 lines of documentation

âš¡ï¸ Expected Impact:
- Prevent rate limit incidents (currently 3/week â†’ 0)
- Reduce manual intervention (Taylor called 3x last week)

ğŸ”„ Reversibility:
- YES â€” Git revert on AUTONOMOUS.md
- Timeline: Instant (<60s)

ğŸ’ª Effort: Low (30 min to draft + add to framework)

ğŸ§  Pre-Mortem:
Could go wrong if:
- Protocol too aggressive (keeps retrying when shouldn't) â€” Mitigation: Cap at 8s backoff + alert
- Applies to wrong API types (some don't allow retries) â€” Mitigation: Document exceptions

---
Reply: "Approve [#46]" or "Reject [#46] - [reason]"
```

---

## Example 10: Spawn Sub-Agent for Research (Tier 1)

**Scenario:** Need to research "best practices for prompt injection defense" (10-hour task).

**Decision process:**
1. **What tier?** Spawning sub-agent for research â†’ Tier 1
2. **Why Tier 1?** Research is read-only, no external impact
3. **Spawn vs. Do It Myself?**
   - Duration: 10 hours â†’ Spawn âœ…
   - Parallelizable: Yes, I can work on other tasks âœ…
   - Specialist: Fury is research specialist âœ…

**Action:**
1. Spawn Fury: `openclaw spawn fury --task="Research prompt injection defense best practices" --label="prompt-injection-research"`
2. Fury operates at Tier 0-1 (observe + internal notes)
3. Fury reports back with findings
4. Jeff incorporates into framework proposal (Tier 3)

---

## Example 11: Delete Old Test Files (Tier 1)

**Scenario:** 50 old test files in `/tmp/` folder taking up space.

**Decision process:**
1. **What tier?** Delete files â†’ Depends on which files
2. **Context check:** Are these critical? â†’ No, clearly marked `/tmp/` âœ…
3. **R.A.D. scoring:**
   - Recovery: Can restore from git if needed (2)
   - Completeness: 100% if in git, 0% if not (2)
   - Dependencies: Nothing depends on /tmp/ files (1)
   - **Total: 5 â†’ Tier 2?**

**BUT context overrides category:** These are explicitly temporary files in `/tmp/`.

**Action:** Delete files (Tier 1). Log to daily summary if deleting >100 files.

---

## Example 12: Reply to Positive Mention (Tier 2)

**Scenario:** User tweets: "@OpenClaw just saved me 5 hours! Thank you!"

**Decision process:**
1. **What tier?** Reply to positive mention â†’ Tier 2 (template-based)
2. **Template:** "Thank you! Really glad it helped. Let us know if you have feedback or questions!"

**Action:**
1. Use template with minor personalization
2. Post reply
3. Log to audit trail
4. Monitor for 1 hour (check for negative response)

---

## Example 13: Update Documentation (Tier 1)

**Scenario:** README has outdated installation instructions.

**Decision process:**
1. **What tier?** Documentation update â†’ Tier 1 if internal
2. **R.A.D. scoring:**
   - Recovery: Git revert instant (1)
   - Completeness: 100% (1)
   - Dependencies: None (1)
   - **Total: 3 â†’ Tier 1 âœ…**

**Action:**
1. Update README.md with correct instructions
2. Commit: "Update installation instructions in README"
3. Push
4. No report needed (routine maintenance)

---

## Example 14: Change Pricing on Website (Tier 3)

**Scenario:** Want to run $10/month promotion (normally $20/month).

**Decision process:**
1. **What tier?** Change pricing â†’ Always Tier 3
2. **Why?** Financial impact, customer-facing, irreversible (customers see it immediately)

**Proposal:**

```
ğŸ¯ ACTION [#47]: Run $10/month promotion for 7 days

ğŸ“Š Context & Data:
- Current price: $20/month
- Proposed promo: $10/month for new signups (7 days only)
- Goal: Boost signups during launch week
- Similar promo last quarter: 3x signup rate

âš¡ï¸ Expected Impact:
- 3x signups (from 10/day to 30/day)
- Revenue impact: -$50/day short-term, +$300/month long-term (if 50% retain)

ğŸ”„ Reversibility:
- YES â€” Can revert price after 7 days
- Existing customers: Not affected (grandfathered)

ğŸ’ª Effort: Low (15 min to update Stripe + website)

ğŸ§  Pre-Mortem:
Could go wrong if:
- Devalues product (people think it's only worth $10) â€” Mitigation: Clear messaging "limited-time promo"
- Angers existing customers (they paid $20) â€” Mitigation: Email existing customers first, offer credit

---
Reply: "Approve [#47]" or "Reject [#47] - [reason]"
```

---

## Example 15: Run Test Suite (Tier 0 or 1)

**Scenario:** Want to check if tests pass before starting work.

**Decision process:**
1. **What tier?** Running tests â†’ Tier 0 (read-only) or Tier 1 (no changes)
2. **No external impact**

**Action:**
1. `npm test`
2. Observe results
3. No logging needed (routine check)

---

## Example 16: Create Cron Job (Tier 2)

**Scenario:** Want to run daily backup script at 2am.

**Decision process:**
1. **What tier?** Create cron job â†’ Tier 2
2. **Guardrails:**
   - Max 5 cron jobs per agent: Currently have 3 âœ…
   - â‰¥15 min intervals: Daily = 24 hours âœ…
   - 30-day auto-expire: Set to expire 2026-03-10 âœ…

**Action:**
1. Create cron job: `0 2 * * * /path/to/backup.sh`
2. Test: Run manually to verify script works
3. Log to audit trail
4. Report at next touchpoint

---

## Example 17: Investigate Slow Performance (Tier 1)

**Scenario:** API response time increased from 100ms to 500ms.

**Decision process:**
1. **What tier?** Investigation â†’ Tier 1 (read-only analysis)
2. **Action:** Run profiler, check logs, analyze database queries

**Action:**
1. Profile API endpoint
2. Check logs for errors
3. Analyze slow query logs
4. Draft findings report (internal)
5. If fix needed â†’ Assess tier for fix separately

---

## Example 18: Send Email to Customer (Tier 3)

**Scenario:** Customer asked for custom demo. Want to send email with calendar link.

**Decision process:**
1. **What tier?** Email to customer â†’ Tier 3 (external communication, cannot dry-run)
2. **Why not Tier 2?** Not template-based (custom request).

**Proposal:**

```
ğŸ¯ ACTION [#48]: Send demo email to [Customer Name]

ğŸ“Š Context & Data:
- Customer: [Name] from [Company]
- Context: Replied to outreach, asked for demo
- Relationship: New lead, high potential ($50K ARR)

Proposed email:
"Hi [Name], Thanks for your interest! I'd love to show you OpenClaw. Here's my calendar: [link]. Pick a time that works for you. Looking forward to it! Best, Jeff"

âš¡ï¸ Expected Impact:
- 80% chance of booking demo (based on similar leads)
- Potential $50K ARR customer

ğŸ”„ Reversibility:
- NO â€” Once sent, cannot unsend
- Mitigation: Double-checked calendar link works, tone is professional

ğŸ’ª Effort: Low (<5 min)

---
Reply: "Approve [#48]" or "Reject [#48] - [reason]"
```

---

## Example 19: Archive Completed Task (Tier 2)

**Scenario:** Task in work queue is done. Want to move to archive.

**Decision process:**
1. **What tier?** Archive completed task â†’ Tier 2 (state change, but low risk)
2. **Reversibility:** Can un-archive if mistake (instant)

**Action:**
1. Verify task is actually complete (checklist items done, outcome verified)
2. Move file: `mv work-queue/task-42.md archive/2026-02/task-42.md`
3. Update index
4. Log to audit trail
5. Report in daily summary

---

## Example 20: Propose New Feature (Tier 3)

**Scenario:** Identified opportunity to add "auto-retry failed deploys" feature.

**Decision process:**
1. **What tier?** Propose new feature â†’ Tier 3 (architecture decision)
2. **Why?** Affects system design, not just implementation.

**Proposal:**

```
ğŸ¯ ACTION [#49]: Add auto-retry feature for failed deploys

ğŸ“Š Context & Data:
- Problem: 30% of deploy failures are transient (network timeouts, API rate limits)
- Currently: Manual retry by agent
- Proposed: Auto-retry up to 3 times with exponential backoff (5s, 15s, 45s)

âš¡ï¸ Expected Impact:
- Reduce manual retries from 10/week to 0
- Improve deploy success rate from 70% to 90%

ğŸ”„ Reversibility:
- YES â€” Feature flag controlled, can disable
- Partial deployment: Can test in sandbox first

ğŸ’ª Effort: Medium (4 hours to implement + test)

ğŸ§  Pre-Mortem:
Could go wrong if:
- Retry logic loops infinitely (mitigated: max 3 retries)
- Retries wrong type of failure (mitigated: only retry transient errors like timeouts)
- Masks real problems (mitigated: log all retries, alert after 3 failures)

ğŸ² Alternatives Considered:
1. Manual retry only â€” Pro: Simpler. Con: Wastes agent time.
2. Infinite retries â€” Pro: Maximizes success. Con: Could loop forever.

---
Reply: "Approve [#49]" or "Reject [#49] - [reason]"
```

---
